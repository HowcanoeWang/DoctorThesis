\chapter{General discussion}

\added{
  The general discussion begins by summarizing the limitations of the research (Section~\ref{sec:reslim}). 
  Following that, the discussion focuses on the challenges encountered while implementing smart agriculture technologies in real-field production (Section~\ref{sec:appclg}). 
  Subsequently, potential solutions for future research opportunities are outlined (Section~\ref{sec:respros}).
  }

\section{\replaced{Reseach limitations}{ Conclusions and reflections}} \label{sec:reslim}

\deleted{This is the first study that combined the advances of aerial (high throughput) and close-range (high quality) surveys in plant phenotyping applications to field-grown crops. This Ph.D. thesis aimed to improve the performance of 3D-based plant phenotyping on field-grown broccoli as a representative of row-planted crops having harvestable organs on the top of canopy, using only low-cost \gls{rgb} cameras. Using \gls{uav} for aerial surveys and photogrammetry allows for the efficient acquisition of 2D field maps and 3D models of the crop canopy for the entire farmland. However, due to limitations in survey efficiency and wind blurring caused by propellers, the \gls{uav} cannot fly too close to plants, resulting in inadequate resolution and quality for directly analyzing the broccoli heads at the organ level. This thesis attempted to fuse the close-range and aerial 3D phenotype data, as well as some latest machine learning and deep learning techniques, to accurately and efficiently obtain the position and size of broccoli heads in the field. Furthermore, this thesis also provided a better 3D virtual visualization for those broccoli heads in the field and builds a foundation for digital twins and virtual farmland for smart agriculture.}

% cp 2-4
\deleted{We first developed an almost automated close-range pipeline to obtain the high-quality 3D models of destructively sampled broccoli heads, as a template database. By using the dual-rotation methods and the automated rotation platform, images from different perspectives of broccoli heads for 3D reconstruction were collected without heavy labor. Two pre-trained deep learning networks were used to preprocess these images without paying too much attention to algorithm developing and training data annotation. Afterward, we developed an automated workflow to calculate the 3D-based morphological traits and correct the top direction, which ensured the 3D models of the broccoli head can be used directly for the next step.}

\deleted{Parallel to the close-range pipeline, we also developed the aerial pipeline to obtain the 3D models of the entire field by \gls{uav} photogrammetry. The key idea is to obtain the shape and position of each broccoli head in the field. But the resolution of photogrammetry-produced field maps or 3D models is not enough for accurate head segmentation. To improve the quality and labor for head segmentation, we first fused the raw \gls{uav} images, which have better resolution and quality, and the field map, which has unique geographical coordinates. Then, we fused the time-series data from different growing stages; the seedling stage was used to obtain the position and IDs of each broccoli, which is a very simple detection task; and these positions were used to narrow the image processing area for head segmentation. Lastly, labor-saving active learning was used to interactively annotate the training data for the segmentation deep learning model. The morphological traits of segmented broccoli heads were also calculated, which is fundamental for the final step.}

\deleted{Finally, we fused the close-range and aerial pipelines. By using the paired morphological traits data from those destructively sampled broccoli heads, we trained an \gls{automl} calibration model to further improve the accuracy of aerial head segmentation. Then, the accuracy of head center positions was also calibrated by the piecewise affine transformation. Finally, for each broccoli head from the aerial survey, the closest 3D model was matched and transformed from the close-range high-quality database. After placing those transformed 3D models back into the aerial model, a script was developed for 3D virtual visualization and a better understanding of the head growth status in the field.}

\deleted{Overall, the results of these three research chapters showed that the proposed pipelines including active learning, deep learning, backward projection, auto machine learning, template matching, and data fusion, led to improved performance in the tested broccoli fields from 2020 to 2022. The results and statistical analysis concluded that the research objectives have been achieved and all the source codes are published on GitHub for replication and any usage purposes, we can conclude that the research has made a positive contribution to the 3D-based plant phenotyping and precision agriculture for broccoli farmlands.}

% limitations -> combine all chapters, and new points can be found?
\deleted{Despite the promising results of the experiment in the broccoli field over three years, there is currently no strong evidence that the proposed methods can achieve similar performance in different farmland or vegetables. Since several assumptions of the methods were based on the characteristics of broccoli heads, such as the solid shape of broccoli head when vertically rotating on the rotation platform, small position variation from seeding to heading, the circular shape of the broccoli head, the clear color differences between the crown and stem for broccoli heads, and the flatten mushroom-shaped broccoli crown shape. Hence, the proposed full pipelines cannot be applied directly to vegetables with variate shapes. The full pipelines may still work on the cauliflowers (just change the color from greenish to whitish); For vegetables like sweet potatoes and cabbages with very different shapes, some modules like close-range reconstruction or 3D-based morphological traits calculation may still work, but some kinds of modifications for other parts are expected. Another limitation of the proposed close-range and aerial data fusion is the visibility of targets in both pipelines, at least for the current stage, not directly applicable for sweet potatoes and potatoes whose targets are beneath the soil, which deserve further studies.}

\added{
  Although the three-year experiment conducted in the broccoli field yielded promising outcomes, the study was also subject to certain limitations.
  This section provides a summary of three specific limitations encountered: 
  the overreliance on broccoli-specific algorithms (Subsection~\ref{sec:lackuni}), 
  the lack of real farmland testing (Subsection~\ref{sec:lackvlid}), 
  and inadequate contributions in fieldwork and data collection (Subsection~\ref{sec:lackdata}).
}

\subsection{\added{Lacking universality}} \label{sec:lackuni}

\added{
  This study relied on certain assumptions about the characteristics of broccoli heads when developing the methods and algorithms.
  However, at present, there is insufficient evidence to support the claim that the proposed methods can achieve comparable results across various farmland or plant species.
}

\added{
  In Chapter 2, an important assumption for the high-quality 3D reconstruction pipeline is that the broccoli head remains rigid and does not change when vertically rotated on the rotation platform. 
  This assumption allows for the alignment and production of good quality 3D models through \gls{sfm}-\gls{mvs} algorithms using images captured from different view angles. 
  While this assumption holds for cauliflowers, sweet potatoes, and fruits like apples and oranges, whose bodies are almost rigid, it does not hold for plants with soft stems, leaves and even roots.
  In such cases, the study proposed pipeline is not suitable, and a better solution is to utilize fixed-object methods (Figures \ref{fig:des1}a and \ref{fig:des1}b) to achieve improved results.
}

\added{
  The postprocessing algorithms for broccoli crown segmentation and rotation in this study were also developed based on the characteristics of the broccoli head.
  Specifically, the algorithm combines the distinct color differences between the crown (dark green) and stem (light green) with a 2-class clustering algorithm to separate the two parts.
  Additionally, the flattened, mushroom-shaped form of the broccoli crown is utilized to determine the normal vector in the upward direction.
  These algorithms are specifically designed for broccoli head cases and may not apply to other vegetables and fruits.
}

\added{
  In Chapter 3, the assumption of minimal positional variation in broccoli from seeding to heading is crucial. 
  In our study, we employed the results of seeding position detection to refine the image processing region during the challenging heading stage. 
  The concept of simplifying complex detection or segmentation tasks by incorporating data collected from an earlier period has also proven effective in other application scenarios. 
  For instance, \mbox{\citet{mu_characterization_2018}} successfully obtained the convex hulls of peach tree crowns during the winter season, which were then utilized to guide the demanding crown segmentation task in summer. 
  Similarly, \mbox{\citet{li_multi-source_2023}} accurately located maize positions during the seeding stage, and these positions served as a guide for the challenging segmentation tasks when the maize canopy has severe leaf overlapping. 
  However, this assumption does not apply to targets that frequently change due to wind, such as wheat and sorghum tassels. 
  it is necessary and valuable to develop different processing algorithms to address such cases in the future.
}

\added{
  We utilized EasyIDP as another valuable tool in this chapter, but it is reported to have a potential performance bottleneck. 
  EasyIDP enables the linking of the same broccoli from low-quality geo-referenced map images to high-quality non-geo-referenced raw images, thereby greatly enhancing the accuracy of head segmentation. 
  In our experiment field, which spanned just one to two hectares, no significant performance bottlenecks were observed during the data processing. 
  However, Dr. Wei Guo reported that when processing a large forest area of over 58 hectares with file sizes exceeding 23GB using EasyIDP, the process took over 3 hours. 
  This performance bottleneck needs to be solved to facilitate the widespread application of this approach in large farmlands.
}

\subsection{\added{Lacking real farmland testing}} \label{sec:lackvlid}

\subsection{\added{Lacking full participation}} \label{sec:lackdata}

\added{
  This is a personal limitation rather than the study itself.
  One thing that needs to be pointed out is I did not contribute entirely to the entire process of the broccoli project. 
  The main focus of my doctoral research lies in the development of algorithms and engineering aspects. 
  Many in-field contributions were made by several collaborators.
  For example, the plant materials used in this study were provided by another student, \mbox{\citet{nishida_estimation_2023}}, in the laboratory. To be more specific, the experimental design of obtaining variate broccoli sizes by different fertilizations and the measurement of field data were primarily carried out by Nishida. 
  Meanwhile, the transplanting and daily field management of broccoli were conducted by technicians from ISAS.
  While the operation of the unmanned aerial vehicle (UAV) and data collection were mainly completed by Dr. Wei Guo.
  Additionally, I implemented some parts of the deep learning codes with the assistance of Tang Li from another laboratory. 
  With his assistance, I was able to apply deep learning methods to process certain data and provide technical reserves for subsequent engineering applications.
  Thanks to their help, I was able to focus my efforts on the engineering aspects of indoor reconstruction systems (Chapter 2), 
  the batch processing workflow of aerial data, and the accuracy improvement of spatiotemporal scale fusion (Chapter 3), 
  as well as the calibration, transformation, and matching of the broccoli model across different scales (Chapter 4).
  Such research experience has provided me with the opportunity to engage in interdisciplinary collaboration and have successfully achieved breakthroughs in my area of study. 
}

\added{
  However, this may not be beneficial to my overall academic development in some content. 
  Due to not being involved throughout the experimental process and data collection, it limits my understanding of the physiological and structural aspects of broccoli in the study. 
  It has made me aware of my shortcomings in research and motivated me to address them. 
  For example, during the period of broccoli transplanting, I visited the site several times to observe and inquire about the relevant details of plot settings. 
  When Nishida conducted field measurements and destructive sampling, I assisted with some measurements and destructive sampling work to gain insight into the details of field measurements. 
  Furthermore, when Dr. Wei Guo carried out drone data collection, I took the opportunity to learn the basic procedures of operating a drone and understood the effects of setting overlap, shutter speed, and exposure on the quality of photographs. 
  After this collaboration experience of my doctoral study, I have come to recognize the importance of actively participating in experiments and data collection for future research.
}

\section{\added{Application challenges}} \label{sec:appclg}



\section{Future research prospects} \label{sec:respros}

% automation rotation platform problem
In this thesis, several new approaches or pipelines were proposed to improve the performance of 3D-based plant phenotyping. It was suggested to extend each of them in the future. As mentioned in Chapter 2, the dual-rotation approach for data collection still needs manually change and vertically flip plants, and only applicable to solid plants. A more automated instrument should be developed to further reduce manual operations. For example, by using a track controlled by a stepper motor or robotic arms to achieve automated plant replacement and rotation. For softer plant organs like leaves and flowers, the dual-rotation method may not work due to the structure changing, so the approach needs to be changed by setting up camera arrays at different angles to achieve similar results.

% nerf app
In addition, besides image-based photogrammetry, the latest \gls{nerf} technology is also worth exploring. There is now an application of \gls{nerf} based on the latest iPad's \gls{lidar} sensor for camera position estimation. In our preliminary experiments in early May 2023, especially for landscape plants with complex structures, better 3D models can be obtained than with photogrammetry. However, currently, the iPad needs to be manually moved to match the path guidance in the software. If this process can be interactively realized with a robotic arm, it also has broad potential applications.

% Virtual plants powered crop data analysis and phenotyping applications.
In Chapter 4, the data fusion between close-range and aerial surveys showed a good result in the visualization hidden part of the broccoli head, although based on statistical regression for visualization rather than actual status. As discussed in Chapter 4, for different cultivars of broccoli, more broccoli heads should be collected to provide a sufficient template database to meet more detailed transformation needs. However, the proposed method is facing challenges when dealing with crops with complex structures, such as maize or soybean canopies. On one hand, the severity of occlusion makes it very difficult to distinguish individual maize or soybean; on the other hand, due to the multilateral structure of crops, it is difficult to collect enough samples for template transformation. In this condition, the advent of procedural modeling points very different solutions which use several parameters to control the structure of 3D models. For example, The L-system was used to construct virtual crop models that adjusted the parameters to approximate the real crop by three-view photos \citep{cieslak_l-system_2021}. Although the model obtained using the above method is only structural, it is not realistic enough in terms of detail and appearance. \citet{mikami_hidden_2022} used photo-quality texture mapping on the plant 3D models with relatively simple geometries and finally obtained a very realistic 3D models in texture. In our preliminary experiment, a similar corn model using parameter controls has already been achieved in Blender, but due to the complexity of the research, the ability to repair the corn canopy has not yet been realized. In subsequent studies, we hope to develop a parameter-controlled broccoli model and complete the repair of the corn canopy.

% The plant and its canopy architecture influence the responses and interactions with various environmental factors, which ultimately affects the yield. The conventional analysis methods rely on heavy and repetitive field measured geometry traits along with statistical analysis through whole growing seasons. While the advent of digital twin technology points a very different future, the researchers can operate directly on the virtual plants and preview its impact on the plant immediately \citet{verdouw_digital_2021}. The fundamental in implementing such technology is to present the 3D crop model (virtual plant) accurately in the computer first, and then implement architecture fine-tuning and phenotyping applications on them. This seminar will summarize recent published papers on how this has been achieved.

% Currently, there are three main methods of acquiring virtual plant that can be architecture fine-tuned. 1) By template stitching. chang_3dcap_2022 obtained the database of wheat organ 3D models at different growth stages by destructive sampling and manual measurement of parameters. Then combine those organed to one wheat by random picking and placing with random position angles within the range obtained by real measurements. wen_3d_2021 applied the similar idea for maize. 2) By static deformation. The 3D static model of whole maize (in point cloud format) was obtained by 3D reconstruction. The maize model was then automatically segmented to organs, and these segmented parts were transformed by applying geometric transformations to implement changes in architecture liu_canopy_2021. 3) By parametric approximation. The L-system was used to construct a parameter adjustable virtual crop model and then adjusted the parameters to approximate the real crop by three-view photos cieslak_l-system_2021. This process was also reflected in the implementation of CG modelling. For example, the general shape of the plant was obtained through relatively simple geometries, and then photo-quality texture mapping was used to obtain a very realistic CG model mikami_hidden_2022.

Furthermore, several advanced phenotyping applications can be simulated on the abovementioned virtual 3D plant models. 1) The ray-tracing technologies can be applied to simulate lights within the canopy. 2) The point cloud simulation technology can be used to simulate point clouds from the virtual canopy. For the canopy traits which are easy to get from virtual plants but hard from the real field, the corresponding models between features from the simulated point cloud and traits from the virtual canopy can be trained and then applied to the field-scanned point cloud data to inverse the actual data \citep{liu_estimating_2017}. 3) the CG rendering techniques can decrease the workload of data annotating in the phenotyping data processing by deep learning. The rending engine can yield CG photos that are very close to the real world. At the same time, by adjusting the model texture to solid pure color, the corresponding labeled information for both CG photos \citep{mikami_hidden_2022} and point clouds \citep{chaudhury_3d_2020} can be generated in batch from random virtual canopies.
