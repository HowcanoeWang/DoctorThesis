\chapter{UAV sensing 3D phenotyping pipeline}

% \input{block/broccoli_profit.tex}

\section{Introduction}

% Waste caused by non-standard vegetables is an unavoidable component of food loss in modern society \citep{parfitt_food_2010,teuber_food_2016}. Cosmetic standards (e.g., size, shape, and aesthetics) play an important role in vegetable quality standards in Northern Hemisphere countries \citep{porter_avoidable_2018}. Therefore, vegetables that do not meet this standard cannot be easily sold and are not harvested \citep{garrone_opening_2014}. \citet{porter_avoidable_2018} estimated that over one-third of the total agricultural production (e.g., 51,500 kilotons annually in the European Economic Area) is lost for this reason. For vegetables harvested by mechanical reaping, owing to the uneven growth rate of individual vegetables, some are not harvested at the appropriate time and are discarded. Hence, the development of technologies to predict the optimal time for the whole field harvesting not only increases the effective yield and profit of farmers, but also contributes to sustainable development and the global environment (Sustainable Development Goals [SDG] targets 12.3 and 12.5).

Broccoli (\textit{Brassica oleracea} L.) head is an important component of the global vegetable market;

% Broccoli (\textit{Brassica oleracea} L.) head is an important component of the global vegetable market; however, there is a high percentage of on-farm waste. Its non-edible parts (leaves, stems) account for $> 75\%$ of the above-ground biomass \citep[Table~1]{fink_nitrogen_1999}. For the remaining marketable parts, the variable bud growth rate results in large variations in head size under complex field conditions. As for other vegetables, fresh broccoli has shipping standards (head diameter, weight, shape, etc.); therefore, a certain amount of non-standard harvested head is wasted from one-time mechanical harvesting. Although the conventional method of selective harvesting by hand three times during the growing season could minimize such waste, the labor cost (107 person-hours per hectare) eliminates its profits \citep{blok_effect_2021}. Because the shipping price is highly dependent on head size, the harvest date is essential to determine the proportion of non-standard-size broccoli and the total income for farmers. If the size distribution of all individuals in the broccoli field could be determined and predicted in the short term, it would be possible to set the optimal harvest date to reduce the number of non-standard-size vegetables and minimize food losses. However, it is unrealistic to manually determine the size distribution of all broccoli in the field.

Smart farming, which involves new technologies such as machinery, remote sensing, high-throughput phenotyping, and artificial intelligence in agricultural production, has received considerable attention from researchers, farmers, and governments. The unmanned aerial vehicle (UAV)-based pipeline provides a flexible and cost-efficient method to capture high-resolution images using various lightweight sensors. By using high-resolution UAV images captured over time, it may be possible to estimate the growth of the head size of all individual vegetables. The time-series data of the head size distribution of all broccoli can be used to develop a prediction model for the short-term growth of broccoli heads. If the head size of all individuals can be predicted, combined with the market prices for each size grade, a prediction system for the optimal harvest date can be built. 

However, several challenges must be overcome to develop a broccoli head size estimation pipeline. First, broccoli grades vary by a few centimeters; therefore, a highly accurate estimation is required. In particular, for UAV images from the broccoli field, the head can be hidden by leaves. Second, for agricultural field applications, it is preferable to minimize the number of computation tasks as much as possible. In particular, semantic segmentation for each crop or organ was obtained from images of the entire field using deep learning \citep{bauer_combining_2019,zhou_automated_2022}. Third, deep learning model training is often powered by a large amount of training data and annotations. Efficient acquisition of these data is an urgent need for deep learning applications in agriculture \citep{kierdorf_growliflower_2022}.

In this study, we developed several techniques (backward projection, pre-position-guided head segmentation, and interactive annotation) to overcome the aforementioned challenges and provide a highly accurate and labor-saving pipeline for broccoli head size estimation. The goals of this study were to: (1) develop a general workflow of the broccoli head size prediction pipeline; (2) implement the pipeline for field trials of broccoli growth in 2020 and 2021; and (3) validate the estimated head size by comparison with field measurements. This pipeline also has great potential to be seamlessly interfaced with other cabbage-like crops, including cauliflower, artichoke, and even lettuce. Meanwhile, the use of a simple RGB sensor, not a complex integration of multiple or expensive sensors (i.e., multi-spectral, LiDAR), makes it more applicability and user-friendly for the farmers, farming and the economic sustainability of many economically and socially disadvantaged rural regions. 

\section{Methods}

The general workflow of the broccoli head size measurement pipeline is shown in Fig.~\ref{fig:bro4} and the Supplementary Video \ref{spp:video}. First, time-series data of all broccoli were collected and visualized using a UAV-based pipeline. The pipeline included the following steps:1) aerial data collection; 2) data preprocessing and 3D reconstruction; 3) broccoli position detection using YOLO v5 at the seedling stage; 4) broccoli head segmentation using BiSeNet v2, and; 5) geometry trait calculation. Second, a simple growth model was built using the head size and temperature data. Finally, a profit prediction model was generated according to the market price survey.

\input{figures/bro.fig.4.tex}

\subsection{Plot conditions and field data collection}

Field trials were conducted at the experimental farm of the Institute for Sustainable Agro-ecosystem Services (ISAS), Nishi-Tokyo, Tokyo, Japan ($35^\circ 43'$N, $139^\circ 32'$E) in 2020 and 2021 (Fig.~\ref{fig:bro5}). Detailed meteorological data during the growth period were collected by a local weather station and are shown in Supplementary Table ~\ref{fig:bros2}. The plot sizes were approximately 0.2 and 0.1 ha for 2020 and 2021, respectively. During the 2-year experiment, the same broccoli cultivar (Jet dome) was planted under the same field management. Machine planting of seedlings at 35-cm intervals in rows 70 cm apart is consistent with local commercial broccoli cultivation regimes. 

\input{figures/bro.fig.5.tex}

The field data of the broccoli head size were measured as validation data (ground truth). This was conducted manually every 2‒3 d using both destructive and non-destructive measurement methods. Non-destructive measures were conducted directly in the field and destructive measures were conducted indoors. In 2020, the maximum broccoli head length was measured by the visual judgment of the longest axis. A total of $120 \times 3$ non-destructive and 434 destructive measurements of 7438 individual broccoli were recorded. 

In 2020, we identified the potential of the proposed algorithm. To further validate this algorithm, we improved the measurement method and increased the number of field samples in 2021. The maximum head length was measured using the maximum value of the length in the $0^\circ$, $45^\circ$, $90^\circ$, and $135^\circ$ directions. To increase the variation in the broccoli head for each survey, there was an 8-day interval between seeding in the western and eastern parts (timeline in Fig.~\ref{fig:bro5}, yellow lunar phase). A total of 2,000 ($400 \times 5$) non-destructive and 557 destructive measurements of 3276 individual broccoli were recorded. To reduce the workload, only half of the area (east or west) was measured on a certain day (timeline in Fig.~\ref{fig:bro5}, blue lunar phase). Head length measurements ranged from 2‒25 cm.

\subsection{Data collection and preprocessing}

After transplanting, several ground control points (GCPs) boards were set at the four corners and within the field for UAV data collection. This was an important resource for later 3D reconstruction and time-series alignment. In this study, all GCPs were measured using hemisphere Real Time Kinematic (RTK) differential GNSS devices to obtain geographical coordinates. However, it is recommended but not mandatory. For developing regions without RTK services, the GCPs' coordinates can be replaced by measuring distances (as scalebar corrector) among each GCP and building a referencing map at the very beginning. The relative coordinates of those GCPs on the referencing map can function the same as the actual geographic coordinates for time-series alignment.

Aerial images were collected using a DJI (SZ DJI Technology Co., Ltd. China) Phantom 4 v2 (camera model FC6310s), a DJI Mavic 2 Pro (camera model Hasselblad) in 2020, and a DJI Phantom 4 RTK (camera model FC6310R) in 2021. The image resolution was the same at $5472 \times 3648$ pixels. The flight height in 2020 was initially 15 m and then decreased to 10 m when the broccoli head turned up. The flight height in 2021 was constantly 15 m. Most of the flights were conducted before the field operation, except on May 22 and 26, 2020. On both these days, the destructively sampled broccoli did not exist in the UAV image; hence, the destructive data were linked to the previous flight (the black broken lines in the timeline in Fig.~\ref{fig:bro5}). For all other times, data collected on the same day were paired together.

The configuration of the computer for 3D reconstruction was as follows: Intel CITM, i9-7980XE CPU \@2.6GHz, 64GB RAM, two NVIDIA GeForce GTX 1080Ti GPUS, and Windows 10 Pro 64-bit operating system. Pix4DMapper Pro (Pix4D, S.A., Prilly, Switzerland) was used to perform flight investigations. The default software parameters were used and the GCPs were marked manually on the closest 3‒5 images. The reconstruction parameters, digital orthophoto map (DOM), and digital surface model (DSM) were produced for later use. 

The open-source software package QGIS (\url{www.qgis.org}) was used to prepare and modify GIS shapefiles, such as field boundaries and field grids on the field map (DOM). The field boundary (plot area) was a rectangular region that tightly wrapped around the broccoli (Fig.~\ref{fig:bro5}). It could be used to filter the noise outside the broccoli plot. The long boundary edges were parallel to the ridge direction (Figs.~\ref{fig:bro5} and ~\ref{fig:bro6}b). Grid plots (yellow squares in Fig.~\ref{fig:bro6}b) shared the same direction as that of the broccoli ridge and overlapped the boundary. For each grid, the edge length was 2.5 m (approximately 1000‒1500 pixels) and contained approximately 50‒100 broccolis. 

\input{figures/bro.fig.6.tex}

The LabelMe annotation tool (\url{https://github.com/wkentaro/labelme}) was used to label the training data for the deep learning models. EasyIDP \citep[\url{https://github.com/UTokyo-FieldPhenomics-Lab/EasyIDP}]{wang_easyidp_2021} was used to locate and crop the same field region imagery on the original UAV images when the DOM was not sufficiently clear for head segmentation (also known as backward projection or reverse calculation).

\subsection{Seedling position detection}

The difficulty of detection varied throughout the broccoli growth season. Detection during the seedling stage was simpler than that during the flowering stage, and the latter had complex leaf occlusion. The seedling position of the broccoli was almost the same as that of the broccoli head. Aligned by the GCPs, the positions were consistent through the time-series DOM and DSM of the full growing season. The results from the easy task of detecting the position in the early stage could be directly used for the subsequent complex flower stage (pre-position-guided). This significantly decreased the difficulty and workload of data analysis for broccoli head analysis.

The flight at approximately 1 month after transplanting was used to detect seedling positions (Fig.~\ref{fig:bro5}, dark green circle in April). During this period, most broccoli leaves were sufficiently large to be clearly observed from the DOM, but the leaves were not connected to each other. The uniform light conditions and differentiation between leaves and backgrounds were also taken into consideration when selecting the most suitable detection time.

The broccoli detection procedure is illustrated in Fig~\ref{fig:bro6}a. The full DOM was first split into several small pixel grids (named `sectors', Fig.~\ref{fig:bro6}a) along the DOM pixel matrix as the input of YOLO v5 (\url{https://github.com/ultralytics/yolov5}) by EasyIDP. The edge length of each sector was 1300 pixels and was buffered with 200 pixels (gray L-shape in Fig.~\ref{fig:bro6}a) on the lower right corner ($1300 \times 1300$ to $1500 \times 1500$) to avoid individual division on sector edges. Training data with only two sectors were labeled using LabelMe (Fig.~\ref{fig:bro6}a). 

Subsequently, the YOLO v5 detection model with default settings was trained and applied to all sectors. Outliers and noise outside the broccoli field were filtered by the plot area boundary. The duplicated buffer zone detection results were merged using the non-maximum suppression (NMS) algorithm. The center point of the bounding box was then viewed as the broccoli position. Finally, we manually inspected and adjusted the results in QGIS, ensuring no missing or duplicate detections (Fig.~\ref{fig:bro6}a). The broccoli ID was given from the north to the south of each ridge and ridges from the west to the east by the ridge detection algorithm (Fig.~\ref{fig:bro6}a; please refer to the links in the data availability section for further details). 

\subsection{Broccoli head segmentation}

Leaf movement and occlusion often cause DOM with double mapping, excessive pixelation, and seamline distortions \citep{lin_new_2021}. It is difficult to obtain a DOM that meets the consistent quality of the full field for head size estimation. To manage this situation, the same region on the raw UAV images (rather than that on the DOM) was used for analysis by backward projection \citep{wang_easyidp_2021}, please check the supplemetary material \ref{spp:backward} backward projection methodology for more details. To reduce the workload of segmentation model training, only the area around the broccoli seedling positions was used. Meanwhile, interactive annotation (also referred to as active learning-inspired annotation \citep{ghosal_weakly_2019}) was applied to decrease the workload of label annotation. The workflow is illustrated in Fig.~\ref{fig:bro6}b.

For image data preparation, only flights with visible broccoli heads were chosen for all 12 flight investigations over 2 years (Fig.~\ref{fig:bro5}, dark green circles in Mays). The plot area was divided into grids. For each grid, the grid boundary and broccoli positions were backward-projected onto the closest raw aerial image (Fig.~\ref{fig:bro6}b). Each raw aerial image was cropped into small sectors ($1500 \times 1500$ px) which were located in the center and contained broccoli seedling positions (Fig.~\ref{fig:bro6}b). Only the square area (approximately 100px side length) buffered from the seedling positions was used for broccoli head segmentation (Fig.~\ref{fig:bro6}b) to eliminate the effects of soil and weeds.

Considering the promptness of the interactive annotation, BiSeNet v2 \citep{yu_bisenet_2020} was used as the segmentation model. BiSeNet v2 is a network structure that employs multiple branches to process inputs of different sizes to strike a balance between the efficiency and computational cost \citep[Fig.~1]{yu_bisenet_2020}. The BiSeNetV2 network used in the present study was based on the \url{https://github.com/CoinCheung/BiSeNet} GitHub project. Our data augmentation strategy used both geometric (G) and photometric (P) transformations, similar to \citet{blok_effect_2021}. The G strategy consisted of \textit{ShiftScaleRotate} (shift limit = 0.5, scale limit = 0.2, rotate limit = 90) and \textit{VerticalFlip}, which were used to solve the problem caused by our point-based or position-guided segmentation workflow. Ideally, the input images had only one broccoli in the middle of the input image, but in actual practice, the broccoli head position appeared randomly caused by bud-head growth shifting, or even with the probability of multiple or no broccoli heads in the input images. The P strategy simulated ``cloudy, sunny" and ``day, night" transitions using RGB shift (r shift limit = 25, g shift limit = 25, b shift limit = 25) and \textit{RandomBrightnessContrast} (brightness limit = 0.3, contrast limit = 0.3) to address the effects of different weather and light conditions due to different flight investigations.

Interactive annotation was used to decrease the workload of image labeling \linebreak (Fig.~\ref{fig:bro6}b). Initially, a small number of startup training data (approximately five to ten broccoli heads per flight) were manually marked using LabelMe; then, the segmentation model was trained using the startup data. Next, images were randomly selected and applied to the segmentation results. These results were transformed into LabelMe JSON formats using Python scripts. Subsequently, manual adjustment produced annotations as new training data in LabelMe. The previous steps were iteratively repeated until no significant adjustment was required for the newly applied results.

The verification dataset for the model performance evaluation was also prepared using the previous interactive annotation. The modified intersection of union (IoU) was used as the evaluation metric. In this case, only the segmentation results inside the grid region (Fig.~\ref{fig:bro6}b, red polygon inside the yellow square) were chosen as the final results. The segmentation results attached to the grid bottom and right edge were also removed because of duplication with the neighboring grids. Here, we renamed the modified IoU inside the grid region as ``mid-IoU" (middle IoU).

The segmentation model was first trained using only the 2020 dataset for several iterations until a good performance was achieved. The model was then applied to the 2021 dataset over several iterations. When the model performed well in both years, it was applied to all dataset images, and the segmentation results after the grid boundary filter were saved for the next procedure.

\subsection{Head traits calculation}

The unit of the segmentation polygon in raw aerial images was a pixel, which could not represent the actual head size. However, the actual head size could be calculated using the pixel scale bar from the geo-referenced DOM. The pixel scalebar on the raw images could be derived from the ratio between the grid size in pixels on the raw image and that on the DOM. This concept was then implemented using projective transformation in scikit-image (\url{https://scikit-image.org}). On some locations, one broccoli may have had duplicated polygons; only the polygon with the largest area was retained, which was accelerated by a k-dimensional tree (KD-Tree) in SciPy (\url{https://scipy.org}).

For each polygon of broccoli head, the following geometry traits were calculated: 1) max length and min length, from the side lengths of the minimum area bounding box; 2) perimeter, circularity and area of polygon; 3) area of polygon convex hull; 4) major length, minor length and eccentricity of ellipse has the same second-moments as the polygon. 5) equivalent diameter of circle has the same area as the polygon.

\subsection{Field validation for head traits}

To test the correlation between field-measured length (dependent variable) and aerial measured length (independent variable), the coefficient of determination ($r^2$) using simple linear regression was used as the evaluator. To assess the trends in differences in broccoli size in detail, locally weighted scatterplot smoothing (LOWESS) regression and distribution comparison were also used.

\section{Results}

\subsection{Broccoli position detection}

To provide a general understanding of this procedure, Supplementary Figs.~\ref{fig:bros1}a to f shows some intermediate results during broccoli position detection. As mentioned in the Materials and Methods section, the DOM of the entire broccoli plot was first divided into several small sectors with a buffer zone. For training data preparation, considering the significant differences between the broccoli plant and brown soil, only two representative sectors were chosen as training images. All broccoli were labeled using bounding box (rectangle) annotation in LabelMe (Supplementary Fig.~\ref{fig:bros1}a, example sector). The detection model performed as expected in the other sectors (Supplementary Fig.~\ref{fig:bros1}b: one example sector). The green mask in Supplementary Fig.~\ref{fig:bros1}b shows the buffer zone that overlapped with neighboring sectors, with the aim of avoiding incomplete broccoli detection on the sector boundary. When merging the detection results for all sectors, duplicate detections were removed by the NMS algorithm (black rectangles in Supplementary Fig.~\ref{fig:bros1}c). When adjusting the zoom to the full map view, the removed black duplicates were clearly distributed on the sector boundaries (grid lines). The center of the detected bounding box was viewed as the broccoli position; however, it required manual inspections to correct false detections and missing broccoli. In Supplementary Fig.~\ref{fig:bros1}d, the green dots show the manually corrected (removed) YOLO detection results, and the red dots indicate the final positions used by manual adjustment. Supplementary Figure~\ref{fig:bros1}e shows the results of ridge-line detection, and Supplementary Fig.~\ref{fig:bros1}f shows some results of the automatic broccoli ID assignment. In general, broccoli position detection and semi-automatic labeling functioned as expected.

\subsection{Broccoli head segmentation}

To clearly demonstrate the interactive annotation procedure, Supplementary \linebreak Figs.~\ref{fig:bros1}g to i and Supplementary Table~\ref{tbl:bros1} provide example images and a simple summary from the first to the last iteration. As startup training data, one image was randomly selected from each flight investigation in 2020, and only a few representative broccoli were annotated as simply as possible (Supplementary Fig.~\ref{fig:bros1}g). The BiSeNet model (v0) was then trained using this annotation. For each flight in 2020, one image was randomly selected and applied to the v0 model (Supplementary Fig.~\ref{fig:bros1}h, red mask). The results were manually adjusted and saved as new training data (Supplementary Fig.~\ref{fig:bros1}h, blue boundary). The previous steps were iteratively repeated until the model achieved good segmentation results, and this version (in this case, v2) was used to produce 30 validation data with low labor costs. The model performance was evaluated using validation data.

The detailed model performance for each iteration version is presented in Supplementary Table~\ref{tbl:bros1}. With the proposed guidance of the broccoli position and the buffered mask, even a startup with only a few annotations could achieve a mid-IoU of 78.15\%. The model performance improved considerably after four iterations and achieved a mid-IoU of 88.33\% after the 4th iteration (Supplementary Fig.~\ref{fig:bros1}i). Then, when the v4 model trained by 2020 data was applied to the 2021 data, the performance decreased to 79.16\%, as expected. However, it significantly improved to 91.70\% after one additional iteration with six training data points added from 2021. Meanwhile, broccoli head segmentation was more challenging at an early stage (May 18, 2020, and May 12, 2021, with the lowest mid IoU) when the head size was small. This suggested that weakly supervised annotation improved the model performance and decreased the workload in data annotation with iteration.

\subsection{HD validation}

The full map of all calculated HDs from the UAV is shown in Supplementary Fig.~\ref{fig:bros2}. We found a high correlation between the maximum length of the broccoli head measured by the UAV image and that measured manually in the field (Fig.~\ref{fig:bro1}). The UAV method tended to underestimate broccoli growth (trend line above the reference line). However, the overall distribution of the estimated head size was almost the same between the two groups (UAV vs. manual, Figs.~\ref{fig:bro1}c and d). 

\input{figures/bro.fig.1.tex}


\section{Discussion}

Reducing on-farm food loss (e.g., non-standard-sized vegetables) is one of the prominent goals of sustainable development in agricultural production. The main aim of this work is to test the use of UAV-mounted digital measurements of broccoli head size and their use in monitoring and prediction of optimal harvest time in terms of economic returns for different sellable size classes. In this study, we created a harvest date prediction system based on UAV imagery, machine learning / deep learning (ML/DL), and a growth model by predicting the short-term change in the head size of all individuals ($> 3000$) in the entire broccoli field. Our experiments demonstrated that: (1) the head sizes estimated by UAV imagery were highly correlated with the field measurements; (2) the proportion of non-standard-size and the total income calculated by the hypothetical harvesting changed dramatically between harvest days; (3) predictions for the few days following a particular date of UAV imagery were highly correlated with those estimated by UAV imagery taken on that date; and (4) the optimal harvest date (i.e., the date for the minimum proportion of non-standard-size broccoli and maximum income) could be predicted with high accuracy. These results suggested that our prediction system for the optimal harvest date of broccoli will benefit farmers by reducing food loss and increasing their income. Although the current study focused on broccoli as a model system, this framework could be readily applied to other similar vegetables such as cauliflower, artichoke, and cabbage. Thus, our case study shows that smart farming techniques have great potential to contribute to the sustainable development of vegetable production.

This study showed that the proportion of non-standard-size broccoli and the total income changed rapidly depending on the harvest date. For example, 1 day later or earlier than the optimal harvest date increased the number of non-standard-size broccoli by approximately 5\% and decreased the total income by approximately 20\%; and 2 days later than the optimal harvest date increased the number of non-standard-size broccoli by approximately 15\% and decreased the total profit by approximately 40\%. To the best of our knowledge, such temporal changes in the number of non-standard-size vegetables and the total profit for different harvest dates have not previously been calculated because no technique was available to measure thousands of individual vegetables multiple times with high accuracy. Interestingly, the optimal harvest date was largely unaffected by differences in the shipping price for each grade (Figs.~\ref{fig:bro3}c and d). The optimal harvest date was determined by the spatial variation in broccoli growth, regardless of the shipping price of each grade. The difficulty in setting the harvest date for mechanical harvesting owing to large spatial variation is a common issue in broccoli and other vegetable farms. Thus, predicting the optimal harvest date using our system (or similar systems) has the potential to reduce on-farm food loss and increase the income of vegetable farmers worldwide.

In addition to estimating temporal variations in head size distribution, our pipeline could visualize spatial variations in individual head size (Supplementary Fig.~\ref{fig:bros2}). In the 2021 trial, spatial variation in broccoli size was intentionally created by planting seedlings on two different dates in the eastern and western areas of the field (8 days intervals). When we visualized the individual head sizes, the difference between the eastern and western fields was evident. However, it was difficult to visually observe the differences on the ground. For example, the difference in average head size between the east and west on March 12, 2021, was only 3 cm. Although the uneven growth between the west and east fields in this trial was intentional, such spatial variation can occur unintentionally and is a major challenge, especially in large-scale agriculture \citep{quine_investigation_2002}. In such a large-scale uneven field, farmers can divide their field into several areas and harvest broccoli multiple times. Using our framework, farmers may be able to visualize the spatial variation of their fields, predict their short-term growth, and determine the optimal spatial and temporal harvest strategy.

Although our developed system highlights the benefits and importance of UAV imagery powered by ML/DL for sustainable agricultural development, there are some limitations to its use. First, our system is neither fully automated nor app-based; therefore, farmers without computer science backgrounds cannot use this system directly in their fields. However, because the source code is open to the public (\url{https://github.com/UTokyo-FieldPhenomics-Lab/UAVbroccoli}), local agricultural institutes and agricultural companies will be able to modify and use the system according to their target vegetables and varieties. This study is definitely not a one-stop solution, but as a pioneer to solve the zero-to-one problem in real agriculture production. Second, the predictive model for the head size of each individual may depend on the type of vegetable, cultivar, and growth conditions. For this application, it is necessary to determine the best-fit model for each agricultural field. This requires the first year for repeated field and UAV data collection and modeling and its application in the second year. There has been some skepticism from farmers about modeled predictions of crop yield. Unlike the traditional method conducted by sampling measurement, the proposed method is based on the time-series per-crop investigation. Such high-throughput phenotyping data powers the data-driven model to a new level. Third, manual inspection of the seedling position detection results is required; this step cannot be omitted because this result is the basis for subsequent broccoli segmentation. Detection omissions, duplications, and drifts need to be checked manually on a case-by-case basis. Although it saves considerable effort compared to adding them manually one by one, this inspection still requires several hours to complete in large-scale fields. Fourth, the problem of leaf occlusion has not been solved, which remains a challenging problem for plant phenotyping \citep{zhang_applications_2020}. As broccoli heads are essentially round, one approach is to restore the roundness of the stubs. The circularity and eccentricity of the broccoli head may be used to describe the severity of occlusion. The least squares for round fitting can be used, or the deep learning framework ORCNN can be applied to obtain improved recovery results \citep{blok_image_2021}. However, it requires a depth camera and image pairs before and after occlusion as training data is collected on the ground, which is inconvenient for current UAV applications but warrants further study. For example, multi-spectral and even LiDAR sensors are becoming increasingly cheap, combined with the rapid development of AI algorithms, this problem and even this work could be refined without unaffordable cost increasing. Also, integration of the method with other commonly used agronomics practices such as mulching films with bioplastics, could assist in the identification of plants and broccoli heads, particularly when used in conjunction with a multi-spectral sensor. Finally, hardware and software instrument costs should not be omitted. In this study, the UAV with RTK (\$6,500), 3D reconstruction software (\$3,499), and a high-performance computer (\$6,000) for computation limit its widespread use for single farmers. However, even for a small farm (0.2 ha) with 7,000 broccoli plants, only 2 days difference from the optimal harvest date can result in an income loss of almost \$2,000. Larger farms are worth investigating in the future. For companies that provide this type of agricultural consulting service, this one-off investment can be offset by the increased profit in a short time. For those economically and socially disadvantaged rural regions, the RTK or the expense of a base-station is not mandatory. It can be replaced by setting more GCP boards and measuring distances among them as scalebar correctors, to get similar results with relative geographical coordinates. For future work, we will cooperate with local broccoli farmlands to test the proposed system without RTK dependences, and keep improving the algorithm performance on the occlusion area as discussed before. The head quality and transport costs will also be integrated into the system to refine its applicability.

In conclusion, this is a demonstrable application of UAV technology to assist farmers in optimizing financial returns and minimizing food waste rather than the majority of UAV / digital agriculture studies that are aspirations and lack the pipeline to actually help farmers in an applied context. In this study, using UAV imagery and ML/DL, we developed a system for estimating and predicting the head size of whole broccoli with high accuracy and showed that the system can predict the optimal harvest date. This UAV-based prediction system is based on several technical improvements and requires minimal labor and computational costs. Therefore, it could be applied to support broccoli farming, and with modifications, to a variety of similar vegetables (i.e., cabbage, cauliflower, artichoke, and lettuce). Because our developed pipeline uses a simple sensor, not a complex integration of multiple sensors, it would be more applicable and user-friendliness for economically and socially disadvantaged rural regions, and it has the potential to be widely adopted by vegetable farmers worldwide.

\hspace*{\fill}

\noindent \textbf{Acknowledgments}: We thank the technical staff of the Institute for Sustainable Agro-ecosystem Services (ISAS) for the management of broccoli fields. 

\hspace*{\fill}

\noindent \textbf{Author Contributions}: W.G. and Y.F. designed the study. E.N. managed the broccoli field and collected field data. W.G. (and technical staff) collected the UAV images and 3D reconstructed the plots. H.W. created the full UAV image analysis pipeline, and T.L. contributed to the deep learning and interactive annotation coding work. E.N. built the prediction models for income. H.W. and E.N. prepared the figures. H.W., E.N., and T.L. prepared the manuscript. Y.K., W.G., and Y.F. supervised this study.

\hspace*{\fill}

\noindent \textbf{Funding}: This study was partially supported by the Japan Science and Technology Agency (JST) AIP Acceleration Research (JPMJCR21U3), by the Ministry of Agriculture, Forestry and Fisheries (MAFF) ``Research project for technologies to strengthen the international competitiveness of Japan's agriculture and food industry."

% \hspace*{\fill}

% \noindent \textbf{Competing interests}: The authors declare no competing interests nor any potential conflict of interest.

\hspace*{\fill}

\noindent \textbf{Data Availability}: The source code used in this manuscript can be accessed at \url{https://github.com/UTokyo-FieldPhenomics-Lab/UAVbroccoli}. All original UAV image data can be accessed by Google Drive upon request (224GB for 2020 and 72GB for 2021). Although the data used in this manuscript were obtained using Pix4D, we updated the workflow to Metashape, which is easier for batch processing in codes since 2022.


\supplementarysection

\input{appendix/easyidp_method.tex}

\subsection{Supplementary Video}
\label{spp:video}

An illustration video about the general pipeline of this study can be accessed here \url{https://youtu.be/SYuOCVqgtrU}. The background music used in this video is copyright-free music from \url{freepd.com}.

\input{tables/bro.tbl.s1.tex}

\input{tables/bro.tbl.s2.tex}

\input{figures/bro.fig.s1.tex}

\newpage

\begin{landscape}
  \input{figures/bro.fig.s2.tex}
\end{landscape}

% \newpage

% \begin{landscape}
  % \input{figures/bro.fig.s3.tex}
% \end{landscape}